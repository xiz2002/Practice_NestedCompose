services:
  postgres:
    image: postgres:16
    container_name: postgres
    restart: unless-stopped
    volumes:
      - pgdata:/var/lib/postgresql/data
    networks:
      - dev-internal-network
    ports:
      - 5432:5432
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $$POSTGRES_USER -d $$POSTGRES_DB"]
      interval: 5s
      timeout: 3s
      retries: 10
  litellm:
    # build:
    #   context: ./apps/litellm
    #   dockerfile: Dockerfile
    image: docker.litellm.ai/berriai/litellm:main-latest
    container_name: litellm
    restart: unless-stopped
    volumes:
      - ./apps/litellm/config.yaml:/app/config.yaml
    ports:
      - 4000:4000
    networks:
      - dev-internal-network
    depends_on:
      - postgres
      # - ollama
    environment:
      - LITELLM_LOG=INFO
      - LITELLM_MASTER_KEY=${LITE_LLM_MASTER_KEY}
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}?schema=${LITE_LLM_SCHEMA}
      # - DATABASE_SCHEMA=${LITE_LLM_SCHEMA}
      # - SERVER_ROOT_PATH=${LITE_LLM_API_PREFIX}
      - OLLAMA_API_BASE=${OLLAMA_API_BASE}
      - OLLAMA_API_KEY=${OLLAMA_API_KEY}
    command: ["--config", "/app/config.yaml", "--port", "4000"]
    # Windows Host에 접근을 하기 위한 설정.
    # extra_hosts:
    #   - "host.docker.internal:host-gateway"
    # Defines the health check configuration for the container
    healthcheck:
      test:
        - CMD-SHELL
        - python3 -c "import urllib.request; urllib.request.urlopen('http://localhost:4000/health/liveliness')"  # Command to execute for health check
      interval: 30s  # Perform health check every 30 seconds
      timeout: 10s   # Health check command times out after 10 seconds
      retries: 3     # Retry up to 3 times if health check fails
      start_period: 40s  # Wait 40 seconds after container start before beginning health checks
  fastapi:
    build:
      context: ./apps/adk
      dockerfile: Dockerfile
    container_name: webapp
    restart: unless-stopped
    networks:
      - dev-internal-network
    ports:
      - "8000:8000"
      - "8080:8080"
    depends_on:
      - litellm
      - postgres
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
      - POSTGRES_HOST=${POSTGRES_HOST}
      - POSTGRES_PORT=${POSTGRES_PORT}
      - POSTGRES_SCHEMA=${ADK_SCHEMA}
      - LITELLM_PROXY_API_BASE=${LITE_LLM_API_BASE}
      - LITELLM_PROXY_API_KEY=${LITE_LLM_MASTER_KEY}
      - USE_LITELLM_PROXY=TRUE
      # - PREFIX=
  
# Volumes
volumes:
  pgdata:
  # open-webui:

# Networks
networks:
  dev-internal-network:

  # -------------------------------------------------------------------
  # -
  # -------------------------------------------------------------------
  # Windows 로컬 Ollama에 접근. 도커로 올릴는 경우에는 해당 주석을 제거 후 사용
  # ollama:
  #   image: ollama/ollama:latest
  #   # build:
  #   #   context: ./apps/ollama
  #   #   dockerfile: Dockerfile
  #   container_name: ollama
  #   restart: unless-stopped
  #   # volumes:
  #   #   - ollama:/root/.ollama
  #   networks:
  #     - dev-internal-network
  #   ports:
  #     - "11434:11434"
  #   runtime: nvidia # Use "runtime: nvidia" if you have the NVIDIA Container Toolkit installed
  #   environment:
  #     - OLLAMA_KEEP_ALIVE=15m
  # ollama-webui:
  #   image: ghcr.io/open-webui/open-webui:main
  #   container_name: ollama-webui
  #   restart: unless-stopped
  #   volumes:
  #     - open-webui:/app/backend/data
  #   ports:
  #     - 8080:8080
  #   networks:
  #     - dev-internal-network
  #   depends_on:
  #     - ollama
  #   environment: # https://docs.openwebui.com/getting-started/env-configuration#default_models
  #     - OLLAMA_BASE_URLS=${OLLAMA_API_BASE} #comma separated ollama hosts
  #     - ENV=dev
  #     - WEBUI_AUTH=False
  #     - WEBUI_NAME=valiantlynx AI
  #     - WEBUI_URL=${OLLAMA_WEB_BASE}
  #     - WEBUI_SECRET_KEY=${OLLAMA_WEB_SECRET_KEY}
  #     - NO_PROXY=host.docker.internal,localhost,127.0.0.1

